from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sse_starlette.sse import EventSourceResponse
import uvicorn
import asyncio
from langchain_core.messages import HumanMessage
import json
import logging
import os
import redis
from typing import List

# Import your graph-building function
from chatbot.agent import build_graph

# --- 1. Setup Logging ---
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- 2. Initialize FastAPI App & CORS ---
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"], # Your React app's origin
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 3. Compile LangGraph Agent & Connect to Redis ---
try:
    langgraph_app = build_graph()
    # Connect to Redis for storing conversation lists
    redis_client = redis.from_url(os.environ["REDIS_URL"])
except Exception as e:
    logger.critical(f"Failed to build LangGraph or connect to Redis: {e}", exc_info=True)
    raise

# --- 4. Define API Models ---
class ChatRequest(BaseModel):
    query: str
    username: str
    thread_id: str

class Conversation(BaseModel):
    thread_id: str
    title: str

# --- 5. Define API Endpoints ---
@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    # Add the conversation to the user's list of conversations in Redis
    # We use the first message content as a temporary title.
    # A background job could update this later to a title generated by an LLM.
    is_new_conversation = not redis_client.exists(f"thread:{request.thread_id}:title")
    if is_new_conversation:
        redis_client.sadd(f"conversations:{request.username}", request.thread_id)
        redis_client.set(f"thread:{request.thread_id}:title", request.query)

    config = {"configurable": {"thread_id": request.thread_id}}
    input_message = {"messages": [HumanMessage(content=request.query)]}
    
    logger.info(f"Received stream request for thread_id: {request.thread_id} from user: {request.username}")
    
    async def event_stream():
        try:
            async for event in langgraph_app.astream_events(input_message, config, version="v1"):
                event_type = event["event"]
                
                if event_type == "on_chat_model_stream":
                    chunk = event["data"]["chunk"]
                    if chunk.content:
                        yield json.dumps({"type": "token", "data": chunk.content})
                
                elif event_type == "on_chain_end" and event["name"] == "quiz_specialist":
                    quiz_json = event["data"]["output"]["messages"][-1].content
                    logger.info("Sending special 'quiz_json' event")
                    yield json.dumps({"type": "quiz_json", "data": quiz_json})

            logger.info(f"Stream ended for thread_id: {request.thread_id}")
            yield json.dumps({"type": "stream_end"})

        except Exception as e:
            logger.error(f"Error in stream for thread_id {request.thread_id}: {e}", exc_info=True)
            yield json.dumps({"type": "error", "data": str(e)})

    return EventSourceResponse(event_stream())

@app.get("/conversations/{username}", response_model=List[Conversation])
async def get_conversations(username: str):
    """
    Fetches the list of conversation threads for a given user.
    """
    logger.info(f"Fetching conversations for user: {username}")
    thread_ids = redis_client.smembers(f"conversations:{username}")
    conversations = []
    for thread_id_bytes in thread_ids:
        thread_id = thread_id_bytes.decode('utf-8')
        title = redis_client.get(f"thread:{thread_id}:title")
        if title:
            conversations.append(Conversation(thread_id=thread_id, title=title.decode('utf-8')))

    # Sort by the initial query to keep the list stable
    conversations.sort(key=lambda x: x.title)
    logger.info(f"Found {len(conversations)} conversations for user: {username}")
    return conversations

@app.get("/")
def root():
    return {"status": "Chatbot API is running"}

# --- 6. Run the Server ---
if __name__ == "__main__":
    logger.info("Starting Uvicorn server on http://0.0.0.0:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)